{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "## Deep Learning\n",
    "\n",
    "## Project: Build a Traffic Sign Recognition Classifier\n",
    "\n",
    "## Completed by Mukil Kesavan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 0: Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "\n",
    "training_file = \"data/train.p\"\n",
    "testing_file = \"data/test.p\"\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "XX_train, y_train = train['features'], train['labels']\n",
    "XX_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1: Dataset Summary & Exploration\n",
    "\n",
    "The pickled data is a dictionary with 4 key/value pairs:\n",
    "\n",
    "- `'features'` is a 4D array containing raw pixel data of the traffic sign images, (num examples, width, height, channels).\n",
    "- `'labels'` is a 1D array containing the label/class id of the traffic sign. The file `signnames.csv` contains id -> name mappings for each id.\n",
    "- `'sizes'` is a list containing tuples, (width, height) representing the the original width and height the image.\n",
    "- `'coords'` is a list containing tuples, (x1, y1, x2, y2) representing coordinates of a bounding box around the sign in the image. **THESE COORDINATES ASSUME THE ORIGINAL IMAGE. THE PICKLED DATA CONTAINS RESIZED VERSIONS (32 by 32) OF THESE IMAGES**\n",
    "\n",
    "Complete the basic data summary below. Use python, numpy and/or pandas methods to calculate the data summary rather than hard coding the results. For example, the [pandas shape method](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.shape.html) might be useful for calculating some of the summary results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide a Basic Summary of the Data Set Using Python, Numpy and/or Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Replace each question mark with the appropriate value. \n",
    "### Use python, pandas or numpy methods rather than hard coding the results\n",
    "\n",
    "# Number of training examples\n",
    "n_train = train['features'].shape[0]\n",
    "\n",
    "# Number of testing examples.\n",
    "n_test = test['features'].shape[0]\n",
    "\n",
    "# What's the shape of an traffic sign image?\n",
    "image_shape = train['features'][0].shape\n",
    "\n",
    "# How many unique classes/labels there are in the dataset.\n",
    "n_classes = len(set(y_train))\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory visualization of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have provided the following data visualizations to give some insights into the characteristics of the dataset:\n",
    "\n",
    "* Plot 5 random images from the Training set\n",
    "* Show histogram of number of training set images of each sign type\n",
    "* Show histogram of number of testing set images of each sign type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Data exploration visualization code goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "# Visualizations will be shown in the notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "def plotOneOfEachClass(images, labels):\n",
    "    \"\"\" This function will plot a single image\n",
    "    of each traffic sign type.\n",
    "    \"\"\"\n",
    "    oneofeach = {}\n",
    "    uniquelabels = np.unique(labels)\n",
    "    for i in range(len(uniquelabels)):\n",
    "        for j in range(len(labels)):\n",
    "            if labels[j] == i:\n",
    "                oneofeach[i] = j\n",
    "    \n",
    "    f = 1\n",
    "    for v in oneofeach.values():\n",
    "        fig = plt.figure(f, figsize = (2, 2))\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(images[v])\n",
    "        f += 1\n",
    "\n",
    "def plotImages(selImageIndices, images, labels, ptitle = None):\n",
    "    \"\"\" This function will plot the images specified in the\n",
    "    selImageIndices list parameter.\n",
    "    \"\"\"\n",
    "    numImages = len(selImageIndices)\n",
    "    fig = plt.figure()\n",
    "    if ptitle is not None:\n",
    "        fig.suptitle(ptitle, fontsize=\"x-large\")\n",
    "    ii = 1\n",
    "    for si in selImageIndices:\n",
    "        si = si % len(images)\n",
    "        ax = fig.add_subplot(1, numImages, ii)\n",
    "        ax.set_title(labels[si])\n",
    "        plt.axis('off')\n",
    "        plt.imshow(images[si].squeeze())\n",
    "        ii += 1\n",
    "\n",
    "def plotSignHistogram(labels, title):\n",
    "    \"\"\" This function plots the histogram of number of\n",
    "    samples of each traffic sign type.\n",
    "    \"\"\"\n",
    "    indices, counts = np.unique(labels, return_counts = True)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.bar(indices, counts, align = 'center')\n",
    "    ax.set_title(title)\n",
    "    plt.show()\n",
    "\n",
    "randImageIndices = random.sample(range(len(XX_train)), 5)\n",
    "plotImages(randImageIndices, XX_train, y_train, \"Sample Images from Dataset\")\n",
    "plotSignHistogram(y_train, \"Training Set Sign Counts\")\n",
    "plotSignHistogram(y_test, \"Testing Set Sign Counts\")\n",
    "#plotOneOfEachClass(XX_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Step 2: Design and Test a Model Architecture\n",
    "\n",
    "Design and implement a deep learning model that learns to recognize traffic signs. Train and test your model on the [German Traffic Sign Dataset](http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset).\n",
    "\n",
    "Here is the process I follow for classifying traffic signs:\n",
    "\n",
    "1. **Preprocessing**: I first convert the training and testing set images from RGB to grayscale. I do this so that the neural network relies primarily on detecting shapes and contrast patterns for detecting traffic signs, instead of color. Colors tend to have different shades in different lighting conditions and I figured that this might be a source of noisy input to the neural network. Also, I did try normalization (mean shifting) of the images after grayscale transformation, but it did not improve my accuracy beyond any reasonable error margin. So, I've left that out of my pre-processing phase.\n",
    "\n",
    "2. **Validation Set Splitting**: The pickled data provided with the project template has training and testing data. However, we still need a validation set to compute the loss function that will be used to adjust weights over multiple training epochs of the neural network. I split off 5% of images from the training set into the validation set for this purpose and shuffled them so that any inherent ordering of images does not affect learning.\n",
    "\n",
    "3. **Neural Network Architecture**: I have used the LeNet-5 architecture, presented in class for the handwritten character recognition task, as the basis for classifying traffic signs with some modifications. In addition to changing the input layer and output layer shapes to fit the traffic sign dataset, I've also added dropout to convolutional and fully connected layers so as to prevent overfitting the training set. I used less aggressive droput (0.25) at the convolutional layers early on in the network to make sure that a good amount of input information is passed along the network and used more aggressive dropout (0.5) in the fully connected layers to prevent overfitting. This gave me a good 3-4% improvement in accuracy over the testing set. \n",
    "\n",
    "4. **Training**: I used a batch size of 128 images, learning rate of 0.001 (with the more sophisticated adam optimizer) and 25 epochs to train the neural network. I experimented with different values and found that this combination gave me the best tradeoff between system memory usage and preventing overtraining (or overfitting to the training set well past any significant improvements to validation set accuracy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process the Data Set (normalization, grayscale, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Convert Images to GrayScale\n",
    "\n",
    "from skimage.color import rgb2gray\n",
    "import numpy as np\n",
    "\n",
    "def convertToGrayscale(img):\n",
    "    img = rgb2gray(img)\n",
    "    img.shape += (1, )\n",
    "    return img\n",
    "\n",
    "X_train = convertToGrayscale(XX_train)\n",
    "X_test = convertToGrayscale(XX_test)\n",
    "\n",
    "XP = [XX_train[0], X_train[0]]\n",
    "yp = [\"\", \"\"]\n",
    "plotImages([0, 1], XP, yp, \"Sample Image Transormation (Grayscale)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data into Training, Validation and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Split the data into training/validation/testing sets here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=0.05,\n",
    "    random_state=832289)\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "X_validation, y_validation = shuffle(X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Define your architecture here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "keep_prob_conv = tf.placeholder(tf.float32)\n",
    "keep_prob_fc = tf.placeholder(tf.float32)\n",
    "\n",
    "def LeNet5(x):\n",
    "    \n",
    "    #Arguments for tf.truncated_normal\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    \n",
    "    #Weights, Biases & Stride for Different Convolution Layers\n",
    "    weights = {\n",
    "        'l1': tf.Variable(tf.truncated_normal((5, 5, 1, 6), mu, sigma)),\n",
    "        'l2': tf.Variable(tf.truncated_normal((5, 5, 6, 16), mu, sigma)),\n",
    "        'l3': tf.Variable(tf.truncated_normal((400, 120), mu, sigma)),\n",
    "        'l4': tf.Variable(tf.truncated_normal((120, 84), mu, sigma)),\n",
    "        'l5': tf.Variable(tf.truncated_normal((84, 43), mu, sigma)),\n",
    "    }\n",
    "    \n",
    "    biases = {\n",
    "        'l1': tf.Variable(tf.zeros(6)),\n",
    "        'l2': tf.Variable(tf.zeros(16)),\n",
    "        'l3': tf.Variable(tf.zeros(120)),\n",
    "        'l4': tf.Variable(tf.zeros(84)),\n",
    "        'l5': tf.Variable(tf.zeros(43)),\n",
    "    }\n",
    "    \n",
    "    cstride = 1\n",
    "    cpadding = \"VALID\"\n",
    "\n",
    "    #Pooling Layer Parameters\n",
    "    pstride = 2\n",
    "    pks = pstride\n",
    "    ppadding = \"VALID\"\n",
    "\n",
    "    #Layer 1: Convolve, add bias and activate - Input = 32x32x1, Output = 28x28x6\n",
    "    out = tf.nn.conv2d(x, weights['l1'], strides = [1, cstride, cstride, 1], padding = cpadding)\n",
    "    out = tf.nn.bias_add(out, biases['l1'])\n",
    "    out = tf.nn.relu(out)\n",
    "    out = tf.nn.dropout(out, keep_prob_conv)\n",
    "    \n",
    "    #Pooling Layer - Input = 28x28x6, Output = 14x14x6\n",
    "    out = tf.nn.max_pool(out, ksize = [1, pks, pks, 1], strides = [1, pstride, pstride, 1], padding = ppadding)\n",
    "    \n",
    "    #Layer 2: Convolve, add bias and activate - Input = 14x14x6, Output = 10x10x16\n",
    "    out = tf.nn.conv2d(out, weights['l2'], strides = [1, cstride, cstride, 1], padding = cpadding)\n",
    "    out = tf.nn.bias_add(out, biases['l2'])\n",
    "    out = tf.nn.relu(out)\n",
    "    out = tf.nn.dropout(out, keep_prob_conv)\n",
    "    \n",
    "    #Pooling Layer - Input = 10x10x16, Output = 5x5x16\n",
    "    out = tf.nn.max_pool(out, ksize = [1, pks, pks, 1], strides = [1, pstride, pstride, 1], padding = ppadding)\n",
    "    \n",
    "    #Flatten - Input = 5x5x16, Output = 400\n",
    "    out = flatten(out)\n",
    "    \n",
    "    #Layer 3: Fully Connected. Input = 400, Output = 120\n",
    "    out = tf.add(tf.matmul(out, weights['l3']), biases['l3'])\n",
    "    out = tf.nn.relu(out)\n",
    "    out = tf.nn.dropout(out, keep_prob_fc)\n",
    "    \n",
    "    #Layer 4: Fully Connected. Input = 120, Output = 84\n",
    "    out = tf.add(tf.matmul(out, weights['l4']), biases['l4'])\n",
    "    out = tf.nn.relu(out)\n",
    "    out = tf.nn.dropout(out, keep_prob_fc)\n",
    "    \n",
    "    #Layer 5: Fully Connected. Input = 84, Output = 43\n",
    "    logits = tf.add(tf.matmul(out, weights['l5']), biases['l5'])\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Validate and Test the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A validation set can be used to assess how well the model is performing. A low accuracy on the training and validation\n",
    "sets imply underfitting. A high accuracy on the test set but low accuracy on the validation set implies overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Train your model here.\n",
    "### Calculate and report the accuracy on the training and validation set.\n",
    "### Once a final model architecture is selected, \n",
    "### the accuracy on the test set should be calculated and reported as well.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "x = tf.placeholder(tf.float32, (None, 32, 32, 1))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "one_hot_y = tf.one_hot(y, 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "\n",
    "logits = LeNet5(x)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits, one_hot_y)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = LEARNING_RATE)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def evaluate(X_data, y_data, kpc = 1.0, kpfc = 1.0):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y, keep_prob_conv: kpc, keep_prob_fc: kpfc})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y, keep_prob_conv: 0.75, keep_prob_fc: 0.5})\n",
    "            \n",
    "        validation_accuracy = evaluate(X_validation, y_validation)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "    \n",
    "    print(\"Training Done!\")\n",
    "    saver.save(sess, './model/tsign')\n",
    "    print(\"Model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('./model'))\n",
    "    test_accuracy = evaluate(X_test, y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Test a Model on New Images\n",
    "\n",
    "I have created 8 german traffic sign images by cutting out signs from images found freely on the web and youtube videos. I have made sure that at least some of the images have an angle to them (translation - e.g. i6, i8) and have non-optimal lighting (rainy and foggy conditions in i1 and i5). I've also manually classified these images and recorded them in new-signs/classes.csv. This is later used to compute the accuracy of the neural network for the new images. After that, I also output the top 3 predictions for each new image and their corresponding softmax probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Output the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from scipy.misc import imread\n",
    "from scipy.misc import imresize\n",
    "import numpy as np\n",
    "\n",
    "def loadScaledImage(imgpath):\n",
    "    \"\"\"This returns a numpy array representing\n",
    "    the input image, scaled down to the 32x32\n",
    "    input width and height expected by LeNet5.\n",
    "    \"\"\"\n",
    "    img = imread(imgpath, mode='RGB')\n",
    "    res = imresize(img, (32, 32))\n",
    "    return res\n",
    "\n",
    "def loadNewImageData(imgFilenames, imgClassesFile):\n",
    "    \"\"\" Loads new images and their class labels.\n",
    "    \"\"\"\n",
    "    y_new = []\n",
    "    with open(imgClassesFile, mode='r') as cfile:\n",
    "        reader = csv.reader(cfile)\n",
    "        for line in reader:\n",
    "            y_new.append(int(line[1].strip()))\n",
    "\n",
    "    X_new = []\n",
    "    for f in imgFilenames:\n",
    "        img = loadScaledImage(f)\n",
    "        X_new.append(img)\n",
    "    return np.array(X_new), np.array(y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Load the images and plot them here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "NEW_SIGN_FILES = [\n",
    "    \"new-signs/i1.png\",\n",
    "    \"new-signs/i2.png\",\n",
    "    \"new-signs/i3.png\",\n",
    "    \"new-signs/i4.png\",\n",
    "    \"new-signs/i5.png\",\n",
    "    \"new-signs/i6.png\",\n",
    "    \"new-signs/i7.png\",\n",
    "    \"new-signs/i8.png\"\n",
    "]\n",
    "\n",
    "NEW_SIGN_CLASSES_FILE = \"new-signs/classes.csv\"\n",
    "\n",
    "XX_new, y_new = loadNewImageData(NEW_SIGN_FILES, NEW_SIGN_CLASSES_FILE)\n",
    "\n",
    "plotImages(range(len(y_new)), XX_new, y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Pre-process Data\n",
    "\n",
    "X_new = convertToGrayscale(np.array(XX_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the Sign Type for Each Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Run the predictions here and use the model to output the prediction for each image.\n",
    "### Make sure to pre-process the images with the same pre-processing pipeline used earlier.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "softmax_probs = tf.nn.softmax(logits)\n",
    "top3 = tf.nn.top_k(softmax_probs, k = 3)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('./model'))\n",
    "    top_preds = sess.run(top3, feed_dict={x: X_new, y: y_new, keep_prob_conv: 1.0, keep_prob_fc: 1.0})\n",
    "\n",
    "preds = top_preds.indices[:, 0]\n",
    "plotImages(range(len(preds)), XX_new, preds, \"Sign Predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Calculate the accuracy for these 5 new images. \n",
    "### For example, if the model predicted 1 out of 5 signs correctly, it's 20% accurate on these new images.\n",
    "\n",
    "correct_preds = 0\n",
    "for i, j in zip(preds, y_new):\n",
    "    correct_preds += int(i == j)\n",
    "accuracy = float(correct_preds) / len(y_new)\n",
    "print(\"Accuracy on New Images = {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Top 5 Softmax Probabilities For Each Image Found on the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the new images, print out the model's softmax probabilities to show the **certainty** of the model's predictions (limit the output to the top 5 probabilities for each image). [`tf.nn.top_k`](https://www.tensorflow.org/versions/r0.12/api_docs/python/nn.html#top_k) could prove helpful here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Print out the top five softmax probabilities for the predictions on the German traffic sign images found on the web. \n",
    "### Feel free to use as many code cells as needed.\n",
    "from tabulate import tabulate\n",
    "\n",
    "softmax_probs = list(zip(NEW_SIGN_FILES, top_preds.indices.tolist(), top_preds.values.tolist()))\n",
    "\n",
    "print(tabulate(softmax_probs, headers = ['Image', 'Predicted Classes', 'Softmax Probabilities']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: Once you have completed all of the code implementations, you need to finalize your work by exporting the IPython Notebook as an HTML document. Before exporting the notebook to html, all of the code cells need to have been run. You can then export the notebook by using the menu above and navigating to  \\n\",\n",
    "    \"**File -> Download as -> HTML (.html)**. Include the finished document along with this notebook as your submission. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Writeup\n",
    "\n",
    "I have exported this notebook along with outputs as an html file (report.html) in the my repository on github. I have also included a project write up, writeup.md in the repository. Here I explain the results we've seen in the notebook, factors that affect them and options for future improvement. Thanks for taking the time to review!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
